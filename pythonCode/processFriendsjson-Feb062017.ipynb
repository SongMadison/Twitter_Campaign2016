{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the given column info, produce a dataframe\n",
    "#Note\n",
    "##some elements of the downloaded json items are not valid, use try except to get rid of them\n",
    "import re\n",
    "import json\n",
    "import pandas as pd \n",
    "import csv\n",
    "   \n",
    "\n",
    "def json2dataframe(json_file, cols = None, verbose = False):\n",
    "    \"\"\"\n",
    "    json_file, a filepath to a json file containing multiple json objects\n",
    "    cols: extract the selected keys, or extract all the keys, and return a dataframe\n",
    "    verbose: to output the nuber of invalid json lines\n",
    "    rtype: panda DataFrame\n",
    "    \"\"\"\n",
    "    if cols:\n",
    "        data = {}\n",
    "        n_invalids = 0\n",
    "        for c in cols:\n",
    "            data[c] = []\n",
    "        with open (json_file) as f1:\n",
    "            for line in f1:\n",
    "                try:\n",
    "                    line = json.loads(line)\n",
    "                except:\n",
    "                    n_invalids += 1\n",
    "                    continue\n",
    "                if 'id_str' not in line:\n",
    "                    continue\n",
    "                for c in cols:\n",
    "                    try:\n",
    "                        if c not in line or line[c] =={} :\n",
    "                            data[c].append('NA')\n",
    "                        elif  isinstance(line[c][0], str):\n",
    "                            data[c].append(re.sub(\"\\\\s+\",\" \",re.sub(\"[\\n\\r\\t]\", \" \", line[c][0])))\n",
    "                        else:\n",
    "                            data[c].extend(line[c]) #include empty list\n",
    "                    except:\n",
    "                        print (\"ERROR\")\n",
    "        data_df = pd.DataFrame.from_dict(data)\n",
    "    else:\n",
    "        json_list = []\n",
    "        n_invalids = 0\n",
    "        with open (json_file) as f1:\n",
    "            for line in f1:\n",
    "                try:\n",
    "                    line = json.loads(line)\n",
    "                    json_list.append(line)\n",
    "                except:\n",
    "                    n_invalids += 1\n",
    "                    continue           \n",
    "        data_df = pd.DataFrame(json_list) \n",
    "    if verbose: print(\"number of invalid lines removed: \" + str(n_invalids))\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "{\n",
    "\t'default_profile': [False],\n",
    "\t'profile_background_color': ['1A1B1F'],\n",
    "\t'description': [''],\n",
    "\t'location': ['Duluth/Atlanta, GA'],\n",
    "\t'id_str': ['443226440'],\n",
    "\t'contributors_enabled': [False],\n",
    "\t'followers_count': [16],\n",
    "\t'friends_count': [127],\n",
    "\t'name': ['Tony Schlitt'],\n",
    "\t'utc_offset': [-14400],\n",
    "\t'profile_sidebar_border_color': ['181A1E'],\n",
    "\t'profile_background_image_url_https': ['https://abs.twimg.com/images/themes/theme9/bg.gif'],\n",
    "\t'id': [443226440],\n",
    "\t'favourites_count': [226],\n",
    "\t'profile_use_background_image': [True],\n",
    "\t'status': {\n",
    "\t\t'in_reply_to_status_id': {},\n",
    "\t\t'id_str': ['783437675328135173'],\n",
    "\t\t'retweet_count': [1],\n",
    "\t\t'is_quote_status': [False],\n",
    "\t\t'retweeted': [False],\n",
    "\t\t'in_reply_to_user_id': [442246443],\n",
    "\t\t'in_reply_to_screen_name': ['brianhoyt24'],\n",
    "\t\t'truncated': [False],\n",
    "\t\t'source': ['<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>'],\n",
    "\t\t'favorite_count': [1],\n",
    "\t\t'id': [7.83437675328135e+17],\n",
    "\t\t'geo': {},\n",
    "\t\t'contributors': {},\n",
    "\t\t'lang': ['en'],\n",
    "\t\t'favorited': [False],\n",
    "\t\t'created_at': ['Tue Oct 04 22:44:32 +0000 2016'],\n",
    "\t\t'text': ['@brianhoyt24 @FrontOfficeLos I did the same as Hoyt üò¢, but you have to play a \"Woo! off\" between Hoyt and Dimino\\'s woos! üòÇüòÇüòÇ'],\n",
    "\t\t'in_reply_to_user_id_str': ['442246443'],\n",
    "\t\t'coordinates': {},\n",
    "\t\t'in_reply_to_status_id_str': {},\n",
    "\t\t'entities': {\n",
    "\t\t\t'hashtags': [],\n",
    "\t\t\t'symbols': [],\n",
    "\t\t\t'user_mentions': [{\n",
    "\t\t\t\t'indices': [\n",
    "\t\t\t\t\t[0],\n",
    "\t\t\t\t\t[12]\n",
    "\t\t\t\t],\n",
    "\t\t\t\t'screen_name': ['brianhoyt24'],\n",
    "\t\t\t\t'name': ['Happy Hoyt'],\n",
    "\t\t\t\t'id': [442246443],\n",
    "\t\t\t\t'id_str': ['442246443']\n",
    "\t\t\t}, {\n",
    "\t\t\t\t'indices': [\n",
    "\t\t\t\t\t[13],\n",
    "\t\t\t\t\t[28]\n",
    "\t\t\t\t],\n",
    "\t\t\t\t'screen_name': ['FrontOfficeLos'],\n",
    "\t\t\t\t'name': ['Los Medina'],\n",
    "\t\t\t\t'id': [487944445],\n",
    "\t\t\t\t'id_str': ['487944445']\n",
    "\t\t\t}],\n",
    "\t\t\t'urls': []\n",
    "\t\t},\n",
    "\t\t'place': {\n",
    "\t\t\t'bounding_box': {\n",
    "\t\t\t\t'type': ['Polygon'],\n",
    "\t\t\t\t'coordinates': [\n",
    "\t\t\t\t\t[\n",
    "\t\t\t\t\t\t[\n",
    "\t\t\t\t\t\t\t[-85.6052],\n",
    "\t\t\t\t\t\t\t[30.3556]\n",
    "\t\t\t\t\t\t],\n",
    "\t\t\t\t\t\t[\n",
    "\t\t\t\t\t\t\t[-80.7426],\n",
    "\t\t\t\t\t\t\t[30.3556]\n",
    "\t\t\t\t\t\t],\n",
    "\t\t\t\t\t\t[\n",
    "\t\t\t\t\t\t\t[-80.7426],\n",
    "\t\t\t\t\t\t\t[35.0008]\n",
    "\t\t\t\t\t\t],\n",
    "\t\t\t\t\t\t[\n",
    "\t\t\t\t\t\t\t[-85.6052],\n",
    "\t\t\t\t\t\t\t[35.0008]\n",
    "\t\t\t\t\t\t]\n",
    "\t\t\t\t\t]\n",
    "\t\t\t\t]\n",
    "\t\t\t},\n",
    "\t\t\t'place_type': ['admin'],\n",
    "\t\t\t'attributes': {},\n",
    "\t\t\t'country': ['United States'],\n",
    "\t\t\t'contained_within': [],\n",
    "\t\t\t'id': ['7142eb97ae21e839'],\n",
    "\t\t\t'country_code': ['US'],\n",
    "\t\t\t'url': ['https://api.twitter.com/1.1/geo/id/7142eb97ae21e839.json'],\n",
    "\t\t\t'name': ['Georgia'],\n",
    "\t\t\t'full_name': ['Georgia, USA']\n",
    "\t\t}\n",
    "\t},\n",
    "\t'profile_image_url': ['http://pbs.twimg.com/profile_images/1883818109/Al3rB_CCIAAfSdq_normal.jpg'],\n",
    "\t'verified': [False],\n",
    "\t'is_translator': [False],\n",
    "\t'created_at': ['Wed Dec 21 23:35:27 +0000 2011'],\n",
    "\t'profile_background_image_url': ['http://abs.twimg.com/images/themes/theme9/bg.gif'],\n",
    "\t'url': {},\n",
    "\t'profile_link_color': ['2FC2EF'],\n",
    "\t'time_zone': ['Eastern Time (US & Canada)'],\n",
    "\t'is_translation_enabled': [False],\n",
    "\t'statuses_count': [600],\n",
    "\t'has_extended_profile': [False],\n",
    "\t'profile_sidebar_fill_color': ['252429'],\n",
    "\t'notifications': [False],\n",
    "\t'default_profile_image': [False],\n",
    "\t'screen_name': ['printpirate'],\n",
    "\t'geo_enabled': [True],\n",
    "\t'lang': ['en'],\n",
    "\t'listed_count': [0],\n",
    "\t'following': [False],\n",
    "\t'profile_image_url_https': ['https://pbs.twimg.com/profile_images/1883818109/Al3rB_CCIAAfSdq_normal.jpg'],\n",
    "\t'entities': {\n",
    "\t\t'description': {\n",
    "\t\t\t'urls': []\n",
    "\t\t}\n",
    "\t},\n",
    "\t'follow_request_sent': [False],\n",
    "\t'protected': [False],\n",
    "\t'profile_background_tile': [False],\n",
    "\t'profile_text_color': ['666666']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "16\n",
      "number of invalid lines removed: 0\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "#example on small json file\n",
    "cols = ['id_str', 'screen_name', 'name','created_at', 'description', \n",
    "        'location', 'time_zone',  'favourites_count','followers_count',  'friends_count',\n",
    "        'lang', 'listed_count' ,'statuses_count', 'geo_enabled', 'protected' ,'verified'] \n",
    "path = \"../../data/followers_info/followers10.json\"\n",
    "cols1 = ['id_str', 'screen_name','description','followers_count']\n",
    "toys_df1 = json2dataframe(path, cols1)\n",
    "print(len(toys_df1.columns))\n",
    "\n",
    "cols = ['id_str', 'screen_name', 'name','created_at', 'description', \n",
    "        'location', 'time_zone',  'favourites_count','followers_count',  'friends_count',\n",
    "        'lang', 'listed_count' ,'statuses_count', 'geo_enabled', 'protected' ,'verified'] \n",
    "toys_df2 = json2dataframe(path, cols)\n",
    "print(len(toys_df2.columns))\n",
    "\n",
    "toys_df3 = json2dataframe(path, verbose = True)\n",
    "print(len(toys_df3.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                     \n",
       "1                                                     \n",
       "2                                                     \n",
       "3                                                     \n",
       "4    I am very much friendly and jovial and have a ...\n",
       "5                                        ACHS Freshman\n",
       "6    Love taking pictures‚ù§ Single Fun Love shopping...\n",
       "7    I am an Oklahoma State University grad. I have...\n",
       "8    #Election2016 Art Arts & Culture Business & Fi...\n",
       "9                                                     \n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toys_df1.to_csv(\"followers10.csv\", header = False)\n",
    "toys_df1['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of invalid lines removed: 2\n",
      "i=0 is done , sample size: 803920\n",
      "number of invalid lines removed: 1\n",
      "i=1 is done , sample size: 949999\n",
      "number of invalid lines removed: 0\n",
      "i=2 is done , sample size: 949999\n",
      "number of invalid lines removed: 3\n",
      "i=3 is done , sample size: 949996\n",
      "number of invalid lines removed: 3\n",
      "i=4 is done , sample size: 949997\n",
      "number of invalid lines removed: 3\n",
      "i=5 is done , sample size: 850202\n",
      "number of invalid lines removed: 0\n",
      "i=6 is done , sample size: 933486\n"
     ]
    }
   ],
   "source": [
    "#feb 17, 2017\n",
    "cols = ['id_str', 'screen_name','description','followers_count']\n",
    "#decription, need to do text cleaning before write into .csv\n",
    "for i in range(0,7):\n",
    "    if i < 10:\n",
    "        inputpath = \"../../data/followers_info/jsons/trump0\"+str(i)+\".json\"\n",
    "        outputpath = \"../../data/followers_info/csvs/trump0\"+str(i)+\".csv\"\n",
    "    elif i < 100:\n",
    "        inputpath = \"../../data/followers_info/jsons/trump\"+str(i)+\".json\"\n",
    "        outputpath = \"../../data/followers_info/csvs/trump\"+str(i)+\".csv\"\n",
    "    trump_df = json2dataframe(inputpath, cols, verbose = True)  \n",
    "    print (\"i=\" +  str(i) +\" is done , sample size: \" + str(len(trump_df)))\n",
    "    trump_df.to_csv(outputpath,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of invalid lines removed: 1\n",
      "i=7 is done , sample size: 800000\n",
      "number of invalid lines removed: 0\n",
      "i=8 is done , sample size: 800000\n",
      "number of invalid lines removed: 1\n",
      "i=9 is done , sample size: 800000\n",
      "number of invalid lines removed: 1\n",
      "i=10 is done , sample size: 800000\n",
      "number of invalid lines removed: 1\n",
      "i=11 is done , sample size: 800000\n",
      "number of invalid lines removed: 1\n",
      "i=12 is done , sample size: 800000\n",
      "number of invalid lines removed: 0\n",
      "i=13 is done , sample size: 800000\n",
      "number of invalid lines removed: 0\n",
      "i=14 is done , sample size: 800000\n",
      "number of invalid lines removed: 0\n",
      "i=15 is done , sample size: 91887\n"
     ]
    }
   ],
   "source": [
    "#feb 17, 2017\n",
    "cols = ['id_str', 'screen_name','description','followers_count']\n",
    "#decription, need to do text cleaning before write into .csv\n",
    "for i in range(7,16):\n",
    "    if i < 10:\n",
    "        inputpath = \"../../data/followers_info/jsons/trump0\"+str(i)+\".json\"\n",
    "        outputpath = \"../../data/followers_info/csvs/trump0\"+str(i)+\"_new.csv\"\n",
    "    elif i < 100:\n",
    "        inputpath = \"../../data/followers_info/jsons/trump\"+str(i)+\".json\"\n",
    "        outputpath = \"../../data/followers_info/csvs/trump\"+str(i)+\"_new.csv\"\n",
    "    trump_df = json2dataframe(inputpath, cols, verbose = True)  \n",
    "    print (\"i=\" +  str(i) +\" is done , sample size: \" + str(len(trump_df)))\n",
    "    trump_df.to_csv(outputpath,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feb 17, 2017\n",
    "cols = ['id_str', 'screen_name','protected','followers_count']\n",
    "#decription, need to do text cleaning before write into .csv\n",
    "for i in range(0,7):\n",
    "    if i < 10:\n",
    "        inputpath = \"../data/followers_info/jsons/trump0\"+str(i)+\".json\"\n",
    "        outputpath = \"../data/followers_info/dataframes/trump0\"+str(i)+\".csv\"\n",
    "    elif i < 100:\n",
    "        inputpath = \"../data/followers_info/jsons/trump\"+str(i)+\".json\"\n",
    "        outputpath = \"../data/followers_info/jsons/trump\"+str(i)+\".csv\"\n",
    "    trump_df = json2dataframe(inputpath, cols, verbose = True)  \n",
    "    print (\"i=\" +  str(i) +\" is done , sample size: \" + str(len(trump_df)))\n",
    "    trump_df.to_csv(outputpath,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/followers_Network/originalData/friends_random100K_info.jsonis done!\n",
      "../data/followers_Network/originalData/friends_non-random100K_info.jsonis done!\n"
     ]
    }
   ],
   "source": [
    "cols = ['id_str', 'screen_name', 'name','created_at', 'description', \n",
    "        'location', 'time_zone',  'favourites_count','followers_count',  'friends_count',\n",
    "        'lang', 'listed_count' ,'statuses_count', 'geo_enabled', 'protected' ,'verified'] \n",
    "\n",
    "\n",
    "filepath1 = \"../data/followers_Network/originalData/friends_random100K_info.json\"\n",
    "friends_ID_SN_random = json2dataframe(filepath1, cols)\n",
    "print(filepath1 + \" is done!\")\n",
    "\n",
    "filepath2 = \"../data/followers_Network/originalData/friends_non-random100K_info.json\"\n",
    "friends_ID_SN_nonrandom = json2dataframe(filepath2, cols)\n",
    "print(filepath2 + \" is done!\")\n",
    "\n",
    "friends_ID_SN_random.to_csv('../data/followers_Network/friends_random_full_info.csv')\n",
    "friends_ID_SN_nonrandom.to_csv('../data/followers_Network/friends_nonrandom_full_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/followers_Network/originalData/friends_random100K_info.jsonis done!\n",
      "../data/followers_Network/originalData/friends_non-random100K_info.jsonis done!\n"
     ]
    }
   ],
   "source": [
    "#42 columns\n",
    "\"\"\"\n",
    "filepath1 = \"../data/followers_Network/originalData/friends_random100K_info.json\"\n",
    "friends_ID_SN_random = json2dataframe2(filepath1)\n",
    "print(filepath1 + \"is done!\")\n",
    "\n",
    "filepath2 = \"../data/followers_Network/originalData/friends_non-random100K_info.json\"\n",
    "friends_ID_SN_nonrandom = json2dataframe2(filepath2)\n",
    "print(filepath2 + \"is done!\")\n",
    "\n",
    "#friends_ID_SN_random.to_csv('../data/followers_Network/friends_random_full_info.csv')\n",
    "#friends_ID_SN_nonrandom.to_csv('../data/followers_Network/friends_nonrandom_full_info.csv')\n",
    "\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
