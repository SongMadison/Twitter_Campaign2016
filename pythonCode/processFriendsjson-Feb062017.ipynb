{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the given column info, produce a dataframe\n",
    "#Note\n",
    "##some elements of the downloaded json items are not valid, use try except to get rid of them\n",
    "\n",
    "import json\n",
    "import pandas as pd \n",
    "import csv\n",
    "   \n",
    "\n",
    "def json2dataframe(json_file, cols = None, verbose = False):\n",
    "    \"\"\"\n",
    "    json_file, a filepath to a json file containing multiple json objects\n",
    "    cols: extract the selected keys, or extract all the keys, and return a dataframe\n",
    "    verbose: to output the nuber of invalid json lines\n",
    "    rtype: panda DataFrame\n",
    "    \"\"\"\n",
    "    if cols:\n",
    "        data = {}\n",
    "        n_invalids = 0\n",
    "        for c in cols:\n",
    "            data[c] = []\n",
    "        with open (json_file) as f1:\n",
    "            for line in f1:\n",
    "                try:\n",
    "                    line = json.loads(line)\n",
    "                except:\n",
    "                    n_invalids += 1\n",
    "                    continue\n",
    "                if 'id_str' not in line:\n",
    "                    continue\n",
    "                for c in cols:\n",
    "                    try:\n",
    "                        if c not in line or line[c] =={} :\n",
    "                            data[c].extend([''])\n",
    "                        else:\n",
    "                            data[c].extend(line[c])\n",
    "                    except:\n",
    "                        print (line)\n",
    "        data_df = pd.DataFrame.from_dict(data)\n",
    "    else:\n",
    "        json_list = []\n",
    "        n_invalids = 0\n",
    "        with open (json_file) as f1:\n",
    "            for line in f1:\n",
    "                try:\n",
    "                    line = json.loads(line)\n",
    "                    json_list.append(line)\n",
    "                except:\n",
    "                    n_invalids += 1\n",
    "                    continue           \n",
    "        data_df = pd.DataFrame(json_list) \n",
    "    if verbose: print(\"number of invalid lines removed: \" + str(n_invalids))\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "16\n",
      "number of invalid lines removed: 0\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "#example on small json file\n",
    "\n",
    "path = \"../data/followers_info/followers10.json\"\n",
    "cols1 = ['id_str', 'screen_name','description','followers_count']\n",
    "toys_df1 = json2dataframe(path, cols1)\n",
    "print(len(toys_df1.columns))\n",
    "\n",
    "cols = ['id_str', 'screen_name', 'name','created_at', 'description', \n",
    "        'location', 'time_zone',  'favourites_count','followers_count',  'friends_count',\n",
    "        'lang', 'listed_count' ,'statuses_count', 'geo_enabled', 'protected' ,'verified'] \n",
    "toys_df2 = json2dataframe(path, cols)\n",
    "print(len(toys_df2.columns))\n",
    "\n",
    "toys_df3 = json2dataframe(path, verbose = True)\n",
    "print(len(toys_df3.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-e9a74eb913c6>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-e9a74eb913c6>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    a = '[{'message': ['Over capacity'], 'code': [130]}]'\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "records = [line for line in open(path)]\n",
    "json.loads(records[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of invalid lines removed: 1\n",
      "i=7 is done , sample size: 800000\n",
      "number of invalid lines removed: 0\n",
      "i=8 is done , sample size: 800000\n",
      "number of invalid lines removed: 1\n",
      "i=9 is done , sample size: 800000\n",
      "number of invalid lines removed: 1\n",
      "i=10 is done , sample size: 800000\n",
      "number of invalid lines removed: 1\n",
      "i=11 is done , sample size: 800000\n",
      "number of invalid lines removed: 1\n",
      "i=12 is done , sample size: 800000\n",
      "number of invalid lines removed: 0\n",
      "i=13 is done , sample size: 800000\n",
      "number of invalid lines removed: 0\n",
      "i=14 is done , sample size: 800000\n",
      "number of invalid lines removed: 0\n",
      "i=15 is done , sample size: 91887\n"
     ]
    }
   ],
   "source": [
    "#feb 17, 2017\n",
    "cols = ['id_str', 'screen_name','protected','followers_count']\n",
    "#decription, need to do text cleaning before write into .csv\n",
    "for i in range(7,16):\n",
    "    if i < 10:\n",
    "        inputpath = \"../data/followers_info/jsons/trump0\"+str(i)+\".json\"\n",
    "        outputpath = \"../data/followers_info/dataframes/trump0\"+str(i)+\".csv\"\n",
    "    elif i < 100:\n",
    "        inputpath = \"../data/followers_info/jsons/trump\"+str(i)+\".json\"\n",
    "        outputpath = \"../data/followers_info/jsons/trump\"+str(i)+\".csv\"\n",
    "    trump_df = json2dataframe(inputpath, cols, verbose = True)  \n",
    "    print (\"i=\" +  str(i) +\" is done , sample size: \" + str(len(trump_df)))\n",
    "    trump_df.to_csv(outputpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/followers_Network/originalData/friends_random100K_info.jsonis done!\n",
      "../data/followers_Network/originalData/friends_non-random100K_info.jsonis done!\n"
     ]
    }
   ],
   "source": [
    "cols = ['id_str', 'screen_name', 'name','created_at', 'description', \n",
    "        'location', 'time_zone',  'favourites_count','followers_count',  'friends_count',\n",
    "        'lang', 'listed_count' ,'statuses_count', 'geo_enabled', 'protected' ,'verified'] \n",
    "\n",
    "\n",
    "filepath1 = \"../data/followers_Network/originalData/friends_random100K_info.json\"\n",
    "friends_ID_SN_random = json2dataframe(filepath1, cols)\n",
    "print(filepath1 + \" is done!\")\n",
    "\n",
    "filepath2 = \"../data/followers_Network/originalData/friends_non-random100K_info.json\"\n",
    "friends_ID_SN_nonrandom = json2dataframe(filepath2, cols)\n",
    "print(filepath2 + \" is done!\")\n",
    "\n",
    "friends_ID_SN_random.to_csv('../data/followers_Network/friends_random_full_info.csv')\n",
    "friends_ID_SN_nonrandom.to_csv('../data/followers_Network/friends_nonrandom_full_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/followers_Network/originalData/friends_random100K_info.jsonis done!\n",
      "../data/followers_Network/originalData/friends_non-random100K_info.jsonis done!\n"
     ]
    }
   ],
   "source": [
    "#42 columns\n",
    "\"\"\"\n",
    "filepath1 = \"../data/followers_Network/originalData/friends_random100K_info.json\"\n",
    "friends_ID_SN_random = json2dataframe2(filepath1)\n",
    "print(filepath1 + \"is done!\")\n",
    "\n",
    "filepath2 = \"../data/followers_Network/originalData/friends_non-random100K_info.json\"\n",
    "friends_ID_SN_nonrandom = json2dataframe2(filepath2)\n",
    "print(filepath2 + \"is done!\")\n",
    "\n",
    "#friends_ID_SN_random.to_csv('../data/followers_Network/friends_random_full_info.csv')\n",
    "#friends_ID_SN_nonrandom.to_csv('../data/followers_Network/friends_nonrandom_full_info.csv')\n",
    "\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
