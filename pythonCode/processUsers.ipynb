{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# { 'default_profile': [False], 'profile_background_color': ['1A1B1F'], 'description': [''], 'location': ['Duluth/Atlanta, GA'], 'id_str': ['443226440'], 'contributors_enabled': [False], 'followers_count': [16], 'friends_count': [127], 'name': ['Tony Schlitt'], 'utc_offset': [-14400], 'profile_sidebar_border_color': ['181A1E'], 'profile_background_image_url_https': ['https://abs.twimg.com/images/themes/theme9/bg.gif'], 'id': [443226440], 'favourites_count': [226], 'profile_use_background_image': [True], 'status': { 'in_reply_to_status_id': {}, 'id_str': ['783437675328135173'], 'retweet_count': [1], 'is_quote_status': [False], 'retweeted': [False], 'in_reply_to_user_id': [442246443], 'in_reply_to_screen_name': ['brianhoyt24'], 'truncated': [False], 'source': ['Twitter for iPhone'], 'favorite_count': [1], 'id': [7.83437675328135e+17], 'geo': {}, 'contributors': {}, 'lang': ['en'], 'favorited': [False], 'created_at': ['Tue Oct 04 22:44:32 +0000 2016'], 'text': ['@brianhoyt24 @FrontOfficeLos I did the same as Hoyt üò¢, but you have to play a \"Woo! off\" between Hoyt and Dimino\\'s woos! üòÇüòÇüòÇ'], 'in_reply_to_user_id_str': ['442246443'], 'coordinates': {}, 'in_reply_to_status_id_str': {}, 'entities': { 'hashtags': [], 'symbols': [], 'user_mentions': [{ 'indices': [ [0], [12] ], 'screen_name': ['brianhoyt24'], 'name': ['Happy Hoyt'], 'id': [442246443], 'id_str': ['442246443'] }, { 'indices': [ [13], [28] ], 'screen_name': ['FrontOfficeLos'], 'name': ['Los Medina'], 'id': [487944445], 'id_str': ['487944445'] }], 'urls': [] }, 'place': { 'bounding_box': { 'type': ['Polygon'], 'coordinates': [ [ [ [-85.6052], [30.3556] ], [ [-80.7426], [30.3556] ], [ [-80.7426], [35.0008] ], [ [-85.6052], [35.0008] ] ] ] }, 'place_type': ['admin'], 'attributes': {}, 'country': ['United States'], 'contained_within': [], 'id': ['7142eb97ae21e839'], 'country_code': ['US'], 'url': ['https://api.twitter.com/1.1/geo/id/7142eb97ae21e839.json'], 'name': ['Georgia'], 'full_name': ['Georgia, USA'] } }, 'profile_image_url': ['http://pbs.twimg.com/profile_images/1883818109/Al3rB_CCIAAfSdq_normal.jpg'], 'verified': [False], 'is_translator': [False], 'created_at': ['Wed Dec 21 23:35:27 +0000 2011'], 'profile_background_image_url': ['http://abs.twimg.com/images/themes/theme9/bg.gif'], 'url': {}, 'profile_link_color': ['2FC2EF'], 'time_zone': ['Eastern Time (US & Canada)'], 'is_translation_enabled': [False], 'statuses_count': [600], 'has_extended_profile': [False], 'profile_sidebar_fill_color': ['252429'], 'notifications': [False], 'default_profile_image': [False], 'screen_name': ['printpirate'], 'geo_enabled': [True], 'lang': ['en'], 'listed_count': [0], 'following': [False], 'profile_image_url_https': ['https://pbs.twimg.com/profile_images/1883818109/Al3rB_CCIAAfSdq_normal.jpg'], 'entities': { 'description': { 'urls': [] } }, 'follow_request_sent': [False], 'protected': [False], 'profile_background_tile': [False], 'profile_text_color': ['666666'] }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"# extract the given column info, produce a dataframe\\n\",\n",
    "\"#Note :1, the field in user json can be dict or list. this function not handle dict now.\\n\",\n",
    "\"#      the NULL, will give a complete graph, which expand all the dict as well.       \\n\",\n",
    "\"#      2, some lines of the downloaded json items are not valid, use try except to get rid of them\\n\",\n",
    "\n",
    "import re\n",
    "import json\n",
    "import pandas as pd \n",
    "import csv\n",
    "   \n",
    "\n",
    "def json2dataframe(json_file, cols = None, verbose = False):\n",
    "    \"\"\"\n",
    "    json_file, a filepath to a json file containing multiple json objects\n",
    "    cols: extract the selected keys, or extract all the keys, and return a dataframe\n",
    "    verbose: to output the nuber of invalid json lines\n",
    "    rtype: panda DataFrame\n",
    "    \"\"\"\n",
    "    if cols:\n",
    "        data = {}\n",
    "        n_invalids = 0\n",
    "        for c in cols:\n",
    "            data[c] = []\n",
    "        with open (json_file) as f1:\n",
    "            for line in f1:\n",
    "                try:\n",
    "                    line = json.loads(line) #case 1, not valid json, pass\n",
    "                except:\n",
    "                    n_invalids += 1    \n",
    "                    continue\n",
    "                if 'id_str' not in line:   #case 2, valid.json stype, no id_str, pass\n",
    "                    continue\n",
    "                for c in cols:             \n",
    "                    if c not in line or isinstance(line[c], dict) :\n",
    "                        data[c].append('NA_VALUE')\n",
    "                    elif  line[c] == []: #include empty list\n",
    "                        data[c].extend('NA_VALUE') \n",
    "                    else:\n",
    "                        aa = str(line[c][0])\n",
    "                        data[c].append( re.sub(\"\\\\s+\",\" \",re.sub(\"[\\n\\r\\t]\", \" \", aa)) )  \n",
    "        data_df = pd.DataFrame.from_dict(data)\n",
    "    else:\n",
    "        json_list = []\n",
    "        n_invalids = 0\n",
    "        with open (json_file) as f1:\n",
    "            for line in f1:\n",
    "                try:\n",
    "                    line = json.loads(line)\n",
    "                    json_list.append(line)\n",
    "                except:\n",
    "                    n_invalids += 1\n",
    "                    continue           \n",
    "        data_df = pd.DataFrame(json_list) \n",
    "    if verbose: print(\"number of invalid lines removed: \" + str(n_invalids))\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "16\n",
      "number of invalid lines removed: 0\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "#example on small json file\n",
    "cols = ['id_str', 'screen_name', 'name','created_at', 'description', \n",
    "        'location', 'time_zone',  'favourites_count','followers_count',  'friends_count',\n",
    "        'lang', 'listed_count' ,'statuses_count', 'geo_enabled', 'protected' ,'verified'] \n",
    "path = \"../../data/followers_info/followers10.json\"\n",
    "cols1 = ['id_str', 'screen_name','description','followers_count']\n",
    "toys_df1 = json2dataframe(path, cols1)\n",
    "print(len(toys_df1.columns))\n",
    "\n",
    "cols = ['id_str', 'screen_name', 'name','created_at', 'description', \n",
    "        'location', 'time_zone',  'favourites_count','followers_count',  'friends_count',\n",
    "        'lang', 'listed_count' ,'statuses_count', 'geo_enabled', 'protected' ,'verified'] \n",
    "toys_df2 = json2dataframe(path, cols)\n",
    "print(len(toys_df2.columns))\n",
    "\n",
    "toys_df3 = json2dataframe(path, verbose = True)\n",
    "print(len(toys_df3.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                     \n",
       "1                                                     \n",
       "2                                                     \n",
       "3                                                     \n",
       "4    I am very much friendly and jovial and have a ...\n",
       "5                                        ACHS Freshman\n",
       "6    Love taking pictures‚ù§ Single Fun Love shopping...\n",
       "7    I am an Oklahoma State University grad. I have...\n",
       "8    #Election2016 Art Arts & Culture Business & Fi...\n",
       "9                                                     \n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#toys_df1.to_csv(\"followers10.csv\", header = False)\n",
    "toys_df1['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of invalid lines removed: 2\n",
      "i=0 is done , sample size: 803920\n",
      "number of invalid lines removed: 1\n",
      "i=1 is done , sample size: 949999\n",
      "number of invalid lines removed: 0\n",
      "i=2 is done , sample size: 949999\n",
      "number of invalid lines removed: 3\n",
      "i=3 is done , sample size: 949996\n",
      "number of invalid lines removed: 3\n",
      "i=4 is done , sample size: 949997\n",
      "number of invalid lines removed: 3\n",
      "i=5 is done , sample size: 850202\n",
      "number of invalid lines removed: 0\n",
      "i=6 is done , sample size: 933486\n",
      "number of invalid lines removed: 1\n",
      "i=7 is done , sample size: 800000\n",
      "number of invalid lines removed: 0\n",
      "i=8 is done , sample size: 800000\n",
      "number of invalid lines removed: 1\n",
      "i=9 is done , sample size: 800000\n",
      "number of invalid lines removed: 1\n",
      "i=10 is done , sample size: 800000\n",
      "number of invalid lines removed: 1\n",
      "i=11 is done , sample size: 800000\n",
      "number of invalid lines removed: 1\n",
      "i=12 is done , sample size: 800000\n",
      "number of invalid lines removed: 0\n",
      "i=13 is done , sample size: 800000\n",
      "number of invalid lines removed: 0\n",
      "i=14 is done , sample size: 800000\n",
      "number of invalid lines removed: 0\n",
      "i=15 is done , sample size: 91887\n"
     ]
    }
   ],
   "source": [
    "#feb 17, 2017\n",
    "# Mar22,\n",
    "# MAr29\n",
    "cols = ['id_str', 'screen_name','description','followers_count']\n",
    "#decription, need to do text cleaning before write into .csv\n",
    "for i in range(0,16):\n",
    "    if i < 10:\n",
    "        inputpath = \"../../data/followers_info/jsons/trump0\"+str(i)+\".json\"\n",
    "        outputpath = \"../../data/followers_info/csvs/trump0\"+str(i)+\".csv\"\n",
    "    elif i < 100:\n",
    "        inputpath = \"../../data/followers_info/jsons/trump\"+str(i)+\".json\"\n",
    "        outputpath = \"../../data/followers_info/csvs/trump\"+str(i)+\".csv\"\n",
    "    trump_df = json2dataframe(inputpath, cols, verbose = True)  \n",
    "    print (\"i=\" +  str(i) +\" is done , sample size: \" + str(len(trump_df)))\n",
    "    trump_df.to_csv(outputpath,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "number of invalid lines removed: 2\n",
    "i=0 is done , sample size: 803920\n",
    "number of invalid lines removed: 1\n",
    "i=1 is done , sample size: 949999\n",
    "number of invalid lines removed: 0\n",
    "i=2 is done , sample size: 949999\n",
    "number of invalid lines removed: 3\n",
    "i=3 is done , sample size: 949996\n",
    "number of invalid lines removed: 3\n",
    "i=4 is done , sample size: 949997\n",
    "number of invalid lines removed: 3\n",
    "i=5 is done , sample size: 850202\n",
    "number of invalid lines removed: 0\n",
    "i=6 is done , sample size: 933486\n",
    "number of invalid lines removed: 1\n",
    "i=7 is done , sample size: 800000\n",
    "number of invalid lines removed: 0\n",
    "i=8 is done , sample size: 800000\n",
    "number of invalid lines removed: 1\n",
    "i=9 is done , sample size: 800000\n",
    "number of invalid lines removed: 1\n",
    "i=10 is done , sample size: 800000\n",
    "number of invalid lines removed: 1\n",
    "i=11 is done , sample size: 800000\n",
    "number of invalid lines removed: 1\n",
    "i=12 is done , sample size: 800000\n",
    "number of invalid lines removed: 0\n",
    "i=13 is done , sample size: 800000\n",
    "number of invalid lines removed: 0\n",
    "i=14 is done , sample size: 800000\n",
    "number of invalid lines removed: 0\n",
    "i=15 is done , sample size: 91887\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/followers_Network/originalData/friends_random100K_info.jsonis done!\n",
      "../data/followers_Network/originalData/friends_non-random100K_info.jsonis done!\n"
     ]
    }
   ],
   "source": [
    "cols = ['id_str', 'screen_name', 'name','created_at', 'description', \n",
    "        'location', 'time_zone',  'favourites_count','followers_count',  'friends_count',\n",
    "        'lang', 'listed_count' ,'statuses_count', 'geo_enabled', 'protected' ,'verified'] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
