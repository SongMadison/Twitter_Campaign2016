{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2 |Anaconda 4.2.0 (64-bit)| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"# extract the given column info, produce a dataframe\\n\",\n",
    "\"#Note :1, the field in user json can be dict or list. this function not handle dict now.\\n\",\n",
    "\"#      the NULL, will give a complete graph, which expand all the dict as well.       \\n\",\n",
    "\"#      2, some lines of the downloaded json items are not valid, use try except to get rid of them\\n\",\n",
    "\n",
    "import re\n",
    "import json\n",
    "import pandas as pd \n",
    "import csv\n",
    "   \n",
    "\n",
    "def json2dataframe(json_file, cols = None, verbose = False):\n",
    "    \"\"\"\n",
    "    json_file, a filepath to a json file containing multiple json objects\n",
    "    cols: extract the selected keys, or extract all the keys, and return a dataframe\n",
    "    verbose: to output the nuber of invalid json lines\n",
    "    rtype: panda DataFrame\n",
    "    \"\"\"\n",
    "    if cols:\n",
    "        data = {}\n",
    "        n_invalids = 0\n",
    "        for c in cols:\n",
    "            data[c] = []\n",
    "        with open (json_file) as f1:\n",
    "            for line in f1:\n",
    "                try:\n",
    "                    line = json.loads(line) #case 1, not valid json, pass\n",
    "                except:\n",
    "                    n_invalids += 1    \n",
    "                    continue\n",
    "                if 'id_str' not in line:   #case 2, valid.json stype, no id_str, pass\n",
    "                    continue\n",
    "                for c in cols:             \n",
    "                    if c not in line or isinstance(line[c], dict) :\n",
    "                        data[c].append('NA_VALUE')\n",
    "                    elif  line[c] == []: #include empty list\n",
    "                        data[c].extend('NA_VALUE') \n",
    "                    else:\n",
    "                        aa = str(line[c][0])\n",
    "                        data[c].append( re.sub(\"\\\\s+\",\" \",re.sub(\"[\\n\\r\\t]+\", \" \", aa)) )  \n",
    "        data_df = pd.DataFrame.from_dict(data)\n",
    "    else:\n",
    "        json_list = []\n",
    "        n_invalids = 0\n",
    "        with open (json_file) as f1:\n",
    "            for line in f1:\n",
    "                try:\n",
    "                    line = json.loads(line)\n",
    "                    json_list.append(line)\n",
    "                except:\n",
    "                    n_invalids += 1\n",
    "                    continue           \n",
    "        data_df = pd.DataFrame(json_list) \n",
    "    if verbose: print(\"number of invalid lines removed: \" + str(n_invalids))\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 433037\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 383659\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 261750\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 617027\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 373417\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 634730\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 297265\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 150793\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 302642\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 407503\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 291401\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 297055\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 159056\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 642932\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 296724\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 280738\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 253080\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 485684\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 392233\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 642080\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 286652\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 315231\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 285638\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 252335\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 491932\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 332285\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 156747\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 638878\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 742227\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 379227\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 282396\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 356565\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 253695\n",
      "number of invalid lines removed: 0\n",
      "ff is done , sample size: 635055\n"
     ]
    }
   ],
   "source": [
    "#feb 17, 2017\n",
    "# Mar22,\n",
    "# MAr29\n",
    "# April 13\n",
    "#cols = ['id_str', 'screen_name','description','followers_count']\n",
    "cols = ['id_str', 'screen_name', 'name','created_at', 'description', \n",
    "        'location', 'time_zone',  'favourites_count','followers_count',  'friends_count',\n",
    "        'lang', 'listed_count' ,'statuses_count', 'geo_enabled', 'protected' ,'verified'] \n",
    "#decription, need to do text cleaning before write into .cs\n",
    "import os\n",
    "files = os.listdir('/data/SongWang/Twitter_Campaign2016/data/followers_info/jsons/trump2017/jsons/') #python 3\n",
    "#files = os.listdir('.')  #python 2\n",
    "\n",
    "for ff in files:\n",
    "    inputpath = \"/data/SongWang/Twitter_Campaign2016/data/followers_info/jsons/trump2017/jsons/\"+ff\n",
    "    match = re.search('([\\w-]+).([\\w-]+)', ff)\n",
    "    ff1 = match.group(1) +'.csv'\n",
    "    outputpath = \"/data/SongWang/Twitter_Campaign2016/data/followers_info/jsons/trump2017/csvs/\"+ff1 \n",
    "    trump_df = json2dataframe(inputpath, cols, verbose = True)  \n",
    "    print (ff +\" is done , sample size: \" + str(len(trump_df)))\n",
    "    trump_df.to_csv(outputpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part4-1.json is done , sample size: 433037\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part5-2.json is done , sample size: 383659\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-10_info-part12-1.json is done , sample size: 261750\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part10-3.json is done , sample size: 617027\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part6-2.json is done , sample size: 373417\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part7-3.json is done , sample size: 634730\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-12_info-part12-4.json is done , sample size: 297265\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-10_info-part3-5.json is done , sample size: 150793\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part5-1.json is done , sample size: 302642\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-08_info-part2.json is done , sample size: 407503\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part7-1.json is done , sample size: 291401\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-12_info-part12-3.json is done , sample size: 297055\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-10_info-part11-4.json is done , sample size: 159056\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-10_info-part3-4.json is done , sample size: 642932\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-08_info-part1.json is done , sample size: 296724\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part10-1.json is done , sample size: 280738\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-10_info-part8-4.json is done , sample size: 253080\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part5-3.json is done , sample size: 485684\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part11-1.json is done , sample size: 392233\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part9-3.json is done , sample size: 642080\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part8-1.json is done , sample size: 286652\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part6-1.json is done , sample size: 315231\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part9-1.json is done , sample size: 285638\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-10_info-part9-4.json is done , sample size: 252335\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part6-3.json is done , sample size: 491932\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-12_info-part12-2.json is done , sample size: 332285\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-08_info-part3-1.json is done , sample size: 156747\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part8-3.json is done , sample size: 638878\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part3-3.json is done , sample size: 742227\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part4-2.json is done , sample size: 379227\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-10_info-part10-4.json is done , sample size: 282396\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part4-3.json is done , sample size: 356565\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-10_info-part7-4.json is done , sample size: 253695\n",
      "number of invalid lines removed: 0\n",
      "realDonaldTrump2017-11-09_info-part11-3.json is done , sample size: 635055\n"
     ]
    }
   ],
   "source": [
    "#feb 17, 2017\n",
    "# Mar22,\n",
    "# MAr29\n",
    "# April 13\n",
    "#cols = ['id_str', 'screen_name','description','followers_count']\n",
    "cols = ['id_str', 'screen_name','description', \n",
    "        'followers_count'] \n",
    "#decription, need to do text cleaning before write into .cs\n",
    "import os\n",
    "files = os.listdir('/data/SongWang/Twitter_Campaign2016/data/followers_info/jsons/trump2017/jsons/') #python 3\n",
    "#files = os.listdir('.')  #python 2\n",
    "\n",
    "for ff in files:\n",
    "    inputpath = \"/data/SongWang/Twitter_Campaign2016/data/followers_info/jsons/trump2017/jsons/\"+ff\n",
    "    match = re.search('([\\w-]+).([\\w-]+)', ff)\n",
    "    ff1 = match.group(1) +'.csv'\n",
    "    outputpath = \"/data/SongWang/Twitter_Campaign2016/data/followers_info/jsons/trump2017/idsns/\"+ff1 \n",
    "    trump_df = json2dataframe(inputpath, cols, verbose = True)  \n",
    "    print (ff +\" is done , sample size: \" + str(len(trump_df)))\n",
    "    trump_df.to_csv(outputpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice-b@google\n",
      "alice-b\n",
      "google\n"
     ]
    }
   ],
   "source": [
    "s = 'purple alice-b@google.com monkey dishwasher'\n",
    "import re\n",
    "match = re.search('([\\w-]+)@([\\w-]+)', s)\n",
    "if match:\n",
    "    print ( match.group() )   ## 'alice-b@google.com' (the whole match)\n",
    "    print (match.group(1))  ## 'alice-b' (the username, group 1)\n",
    "    print (match.group(2))  ## 'google.com' (the host, group 2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
